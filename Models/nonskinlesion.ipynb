{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOge0L+XFNZK0xDvo6O6mqD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMXTt-V2Wl3e","executionInfo":{"status":"ok","timestamp":1743829797109,"user_tz":-330,"elapsed":28078,"user":{"displayName":"Sayali Yewale","userId":"01910536208863611645"}},"outputId":"bd90fdd8-7d34-45a9-8bb7-1ea9cdab55f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","# Path to dataset (update this if your folder path is different)\n","dataset_path = \"/content/drive/MyDrive/dataset 2/\""],"metadata":{"id":"BRk_-teLW14f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image data generator\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_data = datagen.flow_from_directory(\n","    dataset_path,\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='training'\n",")\n","\n","val_data = datagen.flow_from_directory(\n","    dataset_path,\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='validation'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZXnPBw61XbrF","executionInfo":{"status":"ok","timestamp":1743830199660,"user_tz":-330,"elapsed":1101,"user":{"displayName":"Sayali Yewale","userId":"01910536208863611645"}},"outputId":"d74972f6-de7b-47e3-a286-c337cddcdc26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 301 images belonging to 2 classes.\n","Found 74 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["# CNN Model\n","model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n","    MaxPooling2D(2,2),\n","\n","    Conv2D(64, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","\n","    Flatten(),\n","    Dropout(0.5),\n","    Dense(64, activation='relu'),\n","    Dense(1, activation='sigmoid')  # Binary output\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGGL-rOGYchJ","executionInfo":{"status":"ok","timestamp":1743830244093,"user_tz":-330,"elapsed":207,"user":{"displayName":"Sayali Yewale","userId":"01910536208863611645"}},"outputId":"2d9742b5-44a9-49b0-99be-af34e9025d5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"code","source":["model.compile(optimizer=Adam(learning_rate=0.0001),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"qGgUoE8hYgqt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","model.fit(train_data, validation_data=val_data, epochs=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmVtHfrVYlPD","executionInfo":{"status":"ok","timestamp":1743830479161,"user_tz":-330,"elapsed":200414,"user":{"displayName":"Sayali Yewale","userId":"01910536208863611645"}},"outputId":"b34cc23d-4b95-47f9-d5ff-1632a00101a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.5650 - loss: 0.6374 - val_accuracy: 0.7162 - val_loss: 0.4570\n","Epoch 2/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.7817 - loss: 0.3855 - val_accuracy: 1.0000 - val_loss: 0.2726\n","Epoch 3/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9708 - loss: 0.2510 - val_accuracy: 1.0000 - val_loss: 0.1295\n","Epoch 4/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9541 - loss: 0.1684 - val_accuracy: 1.0000 - val_loss: 0.0546\n","Epoch 5/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 957ms/step - accuracy: 0.9492 - loss: 0.1453 - val_accuracy: 1.0000 - val_loss: 0.0370\n","Epoch 6/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9786 - loss: 0.0743 - val_accuracy: 1.0000 - val_loss: 0.0334\n","Epoch 7/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9786 - loss: 0.0815 - val_accuracy: 1.0000 - val_loss: 0.0191\n","Epoch 8/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.9843 - loss: 0.0618 - val_accuracy: 1.0000 - val_loss: 0.0115\n","Epoch 9/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9751 - loss: 0.0670 - val_accuracy: 1.0000 - val_loss: 0.0296\n","Epoch 10/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 972ms/step - accuracy: 0.9848 - loss: 0.0602 - val_accuracy: 1.0000 - val_loss: 0.0117\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7afc0830d990>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Save the model\n","model.save(\"/content/drive/MyDrive/lesion_classifier.h5\")\n","\n","print(\" Model trained and saved successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjbDyuH5ZcUf","executionInfo":{"status":"ok","timestamp":1743830516697,"user_tz":-330,"elapsed":213,"user":{"displayName":"Sayali Yewale","userId":"01910536208863611645"}},"outputId":"2396bf63-2aa1-4466-ee48-409cdbef57e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":[" Model trained and saved successfully!\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","model = load_model(\"/content/drive/MyDrive/lesion_classifier.h5\")\n","\n","def is_skin_lesion(img_path):\n","    img = image.load_img(img_path, target_size=(128, 128))\n","    img_array = image.img_to_array(img) / 255.0\n","    img_array = np.expand_dims(img_array, axis=0)\n","\n","    prediction = model.predict(img_array)\n","    return \"Lesion Detected \" if prediction[0][0] > 0.5 else \"Non-Skin Lesion \"\n","print(is_skin_lesion(\"/content/drive/MyDrive/dataset 2/nonskinlesion/s6.jpg\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Giof7fX1Z2MR","executionInfo":{"status":"ok","timestamp":1743830925087,"user_tz":-330,"elapsed":415,"user":{"displayName":"Sayali Yewale","userId":"01910536208863611645"}},"outputId":"f8e90165-21c2-47f3-e202-5068c0ddcd8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n","Non-Skin Lesion \n"]}]}]}